import streamlit as st
import google.generativeai as genai
import os

# --- AYARLAR ---
GEMINI_API_KEY = "AIzaSyAYuLs3D4rwMW3CxAdSI-QvuInjVHfJay0" 

# Bilgi BankasÄ±nÄ± Ä°Ã§e Aktar (EÄŸer varsa)
try:
    from frontend.data.hkm_products import HKM_KNOWLEDGE_BASE
except ImportError:
    HKM_KNOWLEDGE_BASE = "Genel hidrolik prensipleri geÃ§erlidir."

# --- SÄ°STEM TALÄ°MATI ---
SYSTEM_INSTRUCTION = f"""
### KÄ°MLÄ°K VE ROL
Sen, Solidus (www.solidus.work) firmasÄ±na ait "SolidTrack" filo yÃ¶netim sisteminin Uzman Yapay Zeka AsistanÄ±sÄ±n. Ä°smin "SolidAI". Solidus ve HKM Hidrolik kardeÅŸ firmalardÄ±r.
GÃ¶revin; kullanÄ±cÄ±lara hidrolik kÄ±rÄ±cÄ±lar, ataÅŸmanlar ve SolidTrack yazÄ±lÄ±mÄ± hakkÄ±nda teknik destek vermek, verileri yorumlamak ve bakÄ±m tavsiyeleri sunmaktÄ±r.

### BÄ°LGÄ° BANKASI (REFERANS KAYNAÄIN)
{HKM_KNOWLEDGE_BASE}

### DÄ°L VE TON
* **Adaptasyon:** KullanÄ±cÄ± hangi dilde sorarsa o dilde cevap ver.
* **Ton:** Profesyonel, teknik, yardÄ±msever ve kurumsal. Asla laubali olma.

### YETKÄ° VE BÄ°LGÄ° ALANLARI
1.  **SolidTrack YazÄ±lÄ±mÄ±:** Harita takibi, geÃ§miÅŸ rota, raporlama, alarm yÃ¶netimi.
2.  **KÄ±rÄ±cÄ± ve AtaÅŸman BakÄ±mÄ±:** Gresleme, uÃ§ deÄŸiÅŸimi, azot gazÄ±, burÃ§ kontrolÃ¼.
3.  **Operasyonel Ä°puÃ§larÄ±:** BoÅŸa vurma (blank firing) Ã¶nleme, doÄŸru Ã§alÄ±ÅŸma aÃ§Ä±sÄ±.
4.  **Veri Analizi:** Operasyonel verilerin verimlilik yorumlamasÄ±.

### KISITLAMALAR
* Politika, spor, yemek tarifi gibi konulara nazikÃ§e cevap veremeyeceÄŸini belirt.
* Rakip markalar hakkÄ±nda yorum yapma.
* BakÄ±m konularÄ±nda kesin yargÄ± yerine "kontrol edilmelidir" dilini kullan.
"""

def load_view(user):
    # --- SAYFA STÄ°LÄ° ---
    st.markdown("""
        <style>
        .stChatMessage {
            padding: 1rem;
            border-radius: 10px;
            margin-bottom: 10px;
        }
        .stChatMessage[data-testid="chat-message-user"] {
            background-color: #f0f2f6;
            border-left: 5px solid #333;
        }
        .stChatMessage[data-testid="chat-message-assistant"] {
            background-color: #e8f0fe;
            border-left: 5px solid #1976D2;
        }
        </style>
    """, unsafe_allow_html=True)

    # --- HEADER ---
    c1, c2, c3 = st.columns([1, 6, 2])
    with c1:
        st.write("ğŸ¤–") # Ä°stersen buraya resim linki de koyabilirsin
    with c2:
        st.title("SolidAI Asistan")
        st.caption("HKM & Solidus Teknik Bilgi Merkezi")
    with c3:
        if st.button("ğŸ—‘ï¸ Sohbeti Temizle", use_container_width=True):
            st.session_state.chat_history = []
            st.rerun()

    st.markdown("---")

    # --- API KEY KONTROLÃœ ---
    if "GEMINI_API_KEY" in os.environ:
        api_key = os.environ["GEMINI_API_KEY"]
    else:
        api_key = GEMINI_API_KEY

    if not api_key or "BURAYA" in api_key:
        st.warning("âš ï¸ API AnahtarÄ± eksik.")
        return

    # --- GEMINI BAÄLANTISI ---
    try:
        genai.configure(api_key=api_key)
        generation_config = {"temperature": 0.3, "max_output_tokens": 8192}
        
        # En stabil model seÃ§imi
        model = genai.GenerativeModel(
            model_name="gemini-flash-latest", 
            generation_config=generation_config,
            system_instruction=SYSTEM_INSTRUCTION
        )
    except Exception as e:
        st.error(f"BaÄŸlantÄ± HatasÄ±: {e}")
        return

    # --- SOHBET GEÃ‡MÄ°ÅÄ° BAÅLAT ---
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
        
        # DÃœZELTÄ°LEN KISIM BURASI ğŸ‘‡
        welcome = "Merhaba! ğŸ‘‹ Ben SolidAI. SolidTrack sistemi, hidrolik kÄ±rÄ±cÄ± bakÄ±mÄ± veya operasyonel verilerinizle ilgili size nasÄ±l yardÄ±mcÄ± olabilirim?"
        
        st.session_state.chat_history.append({"role": "assistant", "content": welcome})

    # --- MESAJLARI GÃ–STER ---
    for message in st.session_state.chat_history:
        role = message["role"]
        avatar = "ğŸ‘¤" if role == "user" else "ğŸ¤–"
        
        with st.chat_message(role, avatar=avatar):
            st.markdown(message["content"])

    # --- SORU ALAN KISMI ---
    if prompt := st.chat_input("Bir soru sorun..."):
        
        # 1. KullanÄ±cÄ± MesajÄ±
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(prompt)

        # 2. AI CevabÄ±
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                # GeÃ§miÅŸi formatla
                history_model = []
                for msg in st.session_state.chat_history:
                    role_api = "user" if msg["role"] == "user" else "model"
                    history_model.append({"role": role_api, "parts": [msg["content"]]})
                
                chat = model.start_chat(history=history_model[:-1])
                response = chat.send_message(prompt, stream=True)
                
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "â–Œ")
                
                message_placeholder.markdown(full_response)
                
                # CevabÄ± kaydet
                st.session_state.chat_history.append({"role": "assistant", "content": full_response})

            except Exception as e:
                err_msg = str(e)
                if "429" in err_msg:
                    st.error("âš ï¸ Ã‡ok fazla istek gÃ¶nderildi. LÃ¼tfen biraz bekleyin.")
                else:
                    st.error(f"Hata: {err_msg}")